{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gdForest on Dementia_2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipayandas97/ML_Notebook_/blob/master/gdForest_on_Dementia_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSjE48LlKL4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "__author__ = \"Pierre-Yves Lablanche\"\n",
        "__email__ = \"plablanche@aims.ac.za\"\n",
        "__license__ = \"MIT\"\n",
        "__version__ = \"0.1.6\"\n",
        "#__status__ = \"Development\"\n",
        "\n",
        "\n",
        "# noinspection PyUnboundLocalVariable\n",
        "class gcForest(object):\n",
        "\n",
        "    def __init__(self, shape_1X=None, n_mgsRFtree=30, window=None, stride=1,\n",
        "                 cascade_test_size=0.2, n_cascadeRF=2, n_cascadeRFtree=101, cascade_layer=np.inf,\n",
        "                 min_samples_mgs=0.1, min_samples_cascade=0.05, tolerance=0.0, n_jobs=1):\n",
        "        \"\"\" gcForest Classifier.\n",
        "        :param shape_1X: int or tuple list or np.array (default=None)\n",
        "            Shape of a single sample element [n_lines, n_cols]. Required when calling mg_scanning!\n",
        "            For sequence data a single int can be given.\n",
        "        :param n_mgsRFtree: int (default=30)\n",
        "            Number of trees in a Random Forest during Multi Grain Scanning.\n",
        "        :param window: int (default=None)\n",
        "            List of window sizes to use during Multi Grain Scanning.\n",
        "            If 'None' no slicing will be done.\n",
        "        :param stride: int (default=1)\n",
        "            Step used when slicing the data.\n",
        "        :param cascade_test_size: float or int (default=0.2)\n",
        "            Split fraction or absolute number for cascade training set splitting.\n",
        "        :param n_cascadeRF: int (default=2)\n",
        "            Number of Random Forests in a cascade layer.\n",
        "            For each pseudo Random Forest a complete Random Forest is created, hence\n",
        "            the total numbe of Random Forests in a layer will be 2*n_cascadeRF.\n",
        "        :param n_cascadeRFtree: int (default=101)\n",
        "            Number of trees in a single Random Forest in a cascade layer.\n",
        "        :param min_samples_mgs: float or int (default=0.1)\n",
        "            Minimum number of samples in a node to perform a split\n",
        "            during the training of Multi-Grain Scanning Random Forest.\n",
        "            If int number_of_samples = int.\n",
        "            If float, min_samples represents the fraction of the initial n_samples to consider.\n",
        "        :param min_samples_cascade: float or int (default=0.1)\n",
        "            Minimum number of samples in a node to perform a split\n",
        "            during the training of Cascade Random Forest.\n",
        "            If int number_of_samples = int.\n",
        "            If float, min_samples represents the fraction of the initial n_samples to consider.\n",
        "        :param cascade_layer: int (default=np.inf)\n",
        "            mMximum number of cascade layers allowed.\n",
        "            Useful to limit the contruction of the cascade.\n",
        "        :param tolerance: float (default=0.0)\n",
        "            Accuracy tolerance for the casacade growth.\n",
        "            If the improvement in accuracy is not better than the tolerance the construction is\n",
        "            stopped.\n",
        "        :param n_jobs: int (default=1)\n",
        "            The number of jobs to run in parallel for any Random Forest fit and predict.\n",
        "            If -1, then the number of jobs is set to the number of cores.\n",
        "        \"\"\"\n",
        "        setattr(self, 'shape_1X', shape_1X)\n",
        "        setattr(self, 'n_layer', 0)\n",
        "        setattr(self, '_n_samples', 0)\n",
        "        setattr(self, 'n_cascadeRF', int(n_cascadeRF))\n",
        "        if isinstance(window, int):\n",
        "            setattr(self, 'window', [window])\n",
        "        elif isinstance(window, list):\n",
        "            setattr(self, 'window', window)\n",
        "        setattr(self, 'stride', stride)\n",
        "        setattr(self, 'cascade_test_size', cascade_test_size)\n",
        "        setattr(self, 'n_mgsRFtree', int(n_mgsRFtree))\n",
        "        setattr(self, 'n_cascadeRFtree', int(n_cascadeRFtree))\n",
        "        setattr(self, 'cascade_layer', cascade_layer)\n",
        "        setattr(self, 'min_samples_mgs', min_samples_mgs)\n",
        "        setattr(self, 'min_samples_cascade', min_samples_cascade)\n",
        "        setattr(self, 'tolerance', tolerance)\n",
        "        setattr(self, 'n_jobs', n_jobs)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\" Training the gcForest on input data X and associated target y.\n",
        "        :param X: np.array\n",
        "            Array containing the input samples.\n",
        "            Must be of shape [n_samples, data] where data is a 1D array.\n",
        "        :param y: np.array\n",
        "            1D array containing the target values.\n",
        "            Must be of shape [n_samples]\n",
        "        \"\"\"\n",
        "        if np.shape(X)[0] != len(y):\n",
        "            raise ValueError('Sizes of y and X do not match.')\n",
        "\n",
        "        mgs_X = self.mg_scanning(X, y)\n",
        "        _ = self.cascade_forest(mgs_X, y)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\" Predict the class probabilities of unknown samples X.\n",
        "        :param X: np.array\n",
        "            Array containing the input samples.\n",
        "            Must be of the same shape [n_samples, data] as the training inputs.\n",
        "        :return: np.array\n",
        "            1D array containing the predicted class probabilities for each input sample.\n",
        "        \"\"\"\n",
        "        mgs_X = self.mg_scanning(X)\n",
        "        cascade_all_pred_prob = self.cascade_forest(mgs_X)\n",
        "        predict_proba = np.mean(cascade_all_pred_prob, axis=0)\n",
        "\n",
        "        return predict_proba\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\" Predict the class of unknown samples X.\n",
        "        :param X: np.array\n",
        "            Array containing the input samples.\n",
        "            Must be of the same shape [n_samples, data] as the training inputs.\n",
        "        :return: np.array\n",
        "            1D array containing the predicted class for each input sample.\n",
        "        \"\"\"\n",
        "        pred_proba = self.predict_proba(X=X)\n",
        "        predictions = np.argmax(pred_proba, axis=1)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def mg_scanning(self, X, y=None):\n",
        "        \"\"\" Performs a Multi Grain Scanning on input data.\n",
        "        :param X: np.array\n",
        "            Array containing the input samples.\n",
        "            Must be of shape [n_samples, data] where data is a 1D array.\n",
        "        :param y: np.array (default=None)\n",
        "        :return: np.array\n",
        "            Array of shape [n_samples, .. ] containing Multi Grain Scanning sliced data.\n",
        "        \"\"\"\n",
        "        setattr(self, '_n_samples', np.shape(X)[0])\n",
        "        shape_1X = getattr(self, 'shape_1X')\n",
        "        if isinstance(shape_1X, int):\n",
        "            shape_1X = [1,shape_1X]\n",
        "        if not getattr(self, 'window'):\n",
        "            setattr(self, 'window', [shape_1X[1]])\n",
        "\n",
        "        mgs_pred_prob = []\n",
        "\n",
        "        for wdw_size in getattr(self, 'window'):\n",
        "            wdw_pred_prob = self.window_slicing_pred_prob(X, wdw_size, shape_1X, y=y)\n",
        "            mgs_pred_prob.append(wdw_pred_prob)\n",
        "\n",
        "        return np.concatenate(mgs_pred_prob, axis=1)\n",
        "\n",
        "    def window_slicing_pred_prob(self, X, window, shape_1X, y=None):\n",
        "        \"\"\" Performs a window slicing of the input data and send them through Random Forests.\n",
        "        If target values 'y' are provided sliced data are then used to train the Random Forests.\n",
        "        :param X: np.array\n",
        "            Array containing the input samples.\n",
        "            Must be of shape [n_samples, data] where data is a 1D array.\n",
        "        :param window: int\n",
        "            Size of the window to use for slicing.\n",
        "        :param shape_1X: list or np.array\n",
        "            Shape of a single sample.\n",
        "        :param y: np.array (default=None)\n",
        "            Target values. If 'None' no training is done.\n",
        "        :return: np.array\n",
        "            Array of size [n_samples, ..] containing the Random Forest.\n",
        "            prediction probability for each input sample.\n",
        "        \"\"\"\n",
        "        n_tree = getattr(self, 'n_mgsRFtree')\n",
        "        min_samples = getattr(self, 'min_samples_mgs')\n",
        "        stride = getattr(self, 'stride')\n",
        "\n",
        "        if shape_1X[0] > 1:\n",
        "            print('Slicing Images...')\n",
        "            sliced_X, sliced_y = self._window_slicing_img(X, window, shape_1X, y=y, stride=stride)\n",
        "        else:\n",
        "            print('Slicing Sequence...')\n",
        "            sliced_X, sliced_y = self._window_slicing_sequence(X, window, shape_1X, y=y, stride=stride)\n",
        "\n",
        "        if y is not None:\n",
        "            n_jobs = getattr(self, 'n_jobs')\n",
        "            prf = RandomForestClassifier(n_estimators=n_tree, max_features='sqrt',\n",
        "                                         min_samples_split=min_samples, oob_score=True, n_jobs=n_jobs)\n",
        "            crf = RandomForestClassifier(n_estimators=n_tree, max_features=1,\n",
        "                                         min_samples_split=min_samples, oob_score=True, n_jobs=n_jobs)\n",
        "            print('Training MGS Random Forests...')\n",
        "            prf.fit(sliced_X, sliced_y)\n",
        "            crf.fit(sliced_X, sliced_y)\n",
        "            setattr(self, '_mgsprf_{}'.format(window), prf)\n",
        "            setattr(self, '_mgscrf_{}'.format(window), crf)\n",
        "            pred_prob_prf = prf.oob_decision_function_\n",
        "            pred_prob_crf = crf.oob_decision_function_\n",
        "\n",
        "        if hasattr(self, '_mgsprf_{}'.format(window)) and y is None:\n",
        "            prf = getattr(self, '_mgsprf_{}'.format(window))\n",
        "            crf = getattr(self, '_mgscrf_{}'.format(window))\n",
        "            pred_prob_prf = prf.predict_proba(sliced_X)\n",
        "            pred_prob_crf = crf.predict_proba(sliced_X)\n",
        "\n",
        "        pred_prob = np.c_[pred_prob_prf, pred_prob_crf]\n",
        "\n",
        "        return pred_prob.reshape([getattr(self, '_n_samples'), -1])\n",
        "\n",
        "    def _window_slicing_img(self, X, window, shape_1X, y=None, stride=1):\n",
        "        \"\"\" Slicing procedure for images\n",
        "        :param X: np.array\n",
        "            Array containing the input samples.\n",
        "            Must be of shape [n_samples, data] where data is a 1D array.\n",
        "        :param window: int\n",
        "            Size of the window to use for slicing.\n",
        "        :param shape_1X: list or np.array\n",
        "            Shape of a single sample [n_lines, n_cols].\n",
        "        :param y: np.array (default=None)\n",
        "            Target values.\n",
        "        :param stride: int (default=1)\n",
        "            Step used when slicing the data.\n",
        "        :return: np.array and np.array\n",
        "            Arrays containing the sliced images and target values (empty if 'y' is None).\n",
        "        \"\"\"\n",
        "        if any(s < window for s in shape_1X):\n",
        "            raise ValueError('window must be smaller than both dimensions for an image')\n",
        "\n",
        "        len_iter_x = np.floor_divide((shape_1X[1] - window), stride) + 1\n",
        "        len_iter_y = np.floor_divide((shape_1X[0] - window), stride) + 1\n",
        "        iterx_array = np.arange(0, stride*len_iter_x, stride)\n",
        "        itery_array = np.arange(0, stride*len_iter_y, stride)\n",
        "\n",
        "        ref_row = np.arange(0, window)\n",
        "        ref_ind = np.ravel([ref_row + shape_1X[1] * i for i in range(window)])\n",
        "        inds_to_take = [ref_ind + ix + shape_1X[1] * iy\n",
        "                        for ix, iy in itertools.product(iterx_array, itery_array)]\n",
        "\n",
        "        sliced_imgs = np.take(X, inds_to_take, axis=1).reshape(-1, window**2)\n",
        "\n",
        "        if y is not None:\n",
        "            sliced_target = np.repeat(y, len_iter_x * len_iter_y)\n",
        "        elif y is None:\n",
        "            sliced_target = None\n",
        "\n",
        "        return sliced_imgs, sliced_target\n",
        "\n",
        "    def _window_slicing_sequence(self, X, window, shape_1X, y=None, stride=1):\n",
        "        \"\"\" Slicing procedure for sequences (aka shape_1X = [.., 1]).\n",
        "        :param X: np.array\n",
        "            Array containing the input samples.\n",
        "            Must be of shape [n_samples, data] where data is a 1D array.\n",
        "        :param window: int\n",
        "            Size of the window to use for slicing.\n",
        "        :param shape_1X: list or np.array\n",
        "            Shape of a single sample [n_lines, n_col].\n",
        "        :param y: np.array (default=None)\n",
        "            Target values.\n",
        "        :param stride: int (default=1)\n",
        "            Step used when slicing the data.\n",
        "        :return: np.array and np.array\n",
        "            Arrays containing the sliced sequences and target values (empty if 'y' is None).\n",
        "        \"\"\"\n",
        "        if shape_1X[1] < window:\n",
        "            raise ValueError('window must be smaller than the sequence dimension')\n",
        "\n",
        "        len_iter = np.floor_divide((shape_1X[1] - window), stride) + 1\n",
        "        iter_array = np.arange(0, stride*len_iter, stride)\n",
        "\n",
        "        ind_1X = np.arange(np.prod(shape_1X))\n",
        "        inds_to_take = [ind_1X[i:i+window] for i in iter_array]\n",
        "        sliced_sqce = np.take(X, inds_to_take, axis=1).reshape(-1, window)\n",
        "\n",
        "        if y is not None:\n",
        "            sliced_target = np.repeat(y, len_iter)\n",
        "        elif y is None:\n",
        "            sliced_target = None\n",
        "\n",
        "        return sliced_sqce, sliced_target\n",
        "\n",
        "    def cascade_forest(self, X, y=None):\n",
        "        \"\"\" Perform (or train if 'y' is not None) a cascade forest estimator.\n",
        "        :param X: np.array\n",
        "            Array containing the input samples.\n",
        "            Must be of shape [n_samples, data] where data is a 1D array.\n",
        "        :param y: np.array (default=None)\n",
        "            Target values. If 'None' perform training.\n",
        "        :return: np.array\n",
        "            1D array containing the predicted class for each input sample.\n",
        "        \"\"\"\n",
        "        if y is not None:\n",
        "            setattr(self, 'n_layer', 0)\n",
        "            test_size = getattr(self, 'cascade_test_size')\n",
        "            max_layers = getattr(self, 'cascade_layer')\n",
        "            tol = getattr(self, 'tolerance')\n",
        "\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "\n",
        "            self.n_layer += 1\n",
        "            prf_crf_pred_ref = self._cascade_layer(X_train, y_train)\n",
        "            accuracy_ref = self._cascade_evaluation(X_test, y_test)\n",
        "            feat_arr = self._create_feat_arr(X_train, prf_crf_pred_ref)\n",
        "\n",
        "            self.n_layer += 1\n",
        "            prf_crf_pred_layer = self._cascade_layer(feat_arr, y_train)\n",
        "            accuracy_layer = self._cascade_evaluation(X_test, y_test)\n",
        "\n",
        "            while accuracy_layer > (accuracy_ref + tol) and self.n_layer <= max_layers:\n",
        "                accuracy_ref = accuracy_layer\n",
        "                prf_crf_pred_ref = prf_crf_pred_layer\n",
        "                feat_arr = self._create_feat_arr(X_train, prf_crf_pred_ref)\n",
        "                self.n_layer += 1\n",
        "                prf_crf_pred_layer = self._cascade_layer(feat_arr, y_train)\n",
        "                accuracy_layer = self._cascade_evaluation(X_test, y_test)\n",
        "\n",
        "            if accuracy_layer < accuracy_ref :\n",
        "                n_cascadeRF = getattr(self, 'n_cascadeRF')\n",
        "                for irf in range(n_cascadeRF):\n",
        "                    delattr(self, '_casprf{}_{}'.format(self.n_layer, irf))\n",
        "                    delattr(self, '_cascrf{}_{}'.format(self.n_layer, irf))\n",
        "                self.n_layer -= 1\n",
        "\n",
        "        elif y is None:\n",
        "            at_layer = 1\n",
        "            prf_crf_pred_ref = self._cascade_layer(X, layer=at_layer)\n",
        "            while at_layer < getattr(self, 'n_layer'):\n",
        "                at_layer += 1\n",
        "                feat_arr = self._create_feat_arr(X, prf_crf_pred_ref)\n",
        "                prf_crf_pred_ref = self._cascade_layer(feat_arr, layer=at_layer)\n",
        "\n",
        "        return prf_crf_pred_ref\n",
        "\n",
        "    def _cascade_layer(self, X, y=None, layer=0):\n",
        "        \"\"\" Cascade layer containing Random Forest estimators.\n",
        "        If y is not None the layer is trained.\n",
        "        :param X: np.array\n",
        "            Array containing the input samples.\n",
        "            Must be of shape [n_samples, data] where data is a 1D array.\n",
        "        :param y: np.array (default=None)\n",
        "            Target values. If 'None' perform training.\n",
        "        :param layer: int (default=0)\n",
        "            Layer indice. Used to call the previously trained layer.\n",
        "        :return: list\n",
        "            List containing the prediction probabilities for all samples.\n",
        "        \"\"\"\n",
        "        n_tree = getattr(self, 'n_cascadeRFtree')\n",
        "        n_cascadeRF = getattr(self, 'n_cascadeRF')\n",
        "        min_samples = getattr(self, 'min_samples_cascade')\n",
        "\n",
        "        n_jobs = getattr(self, 'n_jobs')\n",
        "        prf = RandomForestClassifier(n_estimators=n_tree, max_features='sqrt',\n",
        "                                     min_samples_split=min_samples, oob_score=True, n_jobs=n_jobs)\n",
        "        crf = RandomForestClassifier(n_estimators=n_tree, max_features=1,\n",
        "                                     min_samples_split=min_samples, oob_score=True, n_jobs=n_jobs)\n",
        "\n",
        "        prf_crf_pred = []\n",
        "        if y is not None:\n",
        "            print('Adding/Training Layer, n_layer={}'.format(self.n_layer))\n",
        "            for irf in range(n_cascadeRF):\n",
        "                prf.fit(X, y)\n",
        "                crf.fit(X, y)\n",
        "                setattr(self, '_casprf{}_{}'.format(self.n_layer, irf), prf)\n",
        "                setattr(self, '_cascrf{}_{}'.format(self.n_layer, irf), crf)\n",
        "                prf_crf_pred.append(prf.oob_decision_function_)\n",
        "                prf_crf_pred.append(crf.oob_decision_function_)\n",
        "        elif y is None:\n",
        "            for irf in range(n_cascadeRF):\n",
        "                prf = getattr(self, '_casprf{}_{}'.format(layer, irf))\n",
        "                crf = getattr(self, '_cascrf{}_{}'.format(layer, irf))\n",
        "                prf_crf_pred.append(prf.predict_proba(X))\n",
        "                prf_crf_pred.append(crf.predict_proba(X))\n",
        "\n",
        "        return prf_crf_pred\n",
        "\n",
        "    def _cascade_evaluation(self, X_test, y_test):\n",
        "        \"\"\" Evaluate the accuracy of the cascade using X and y.\n",
        "        :param X_test: np.array\n",
        "            Array containing the test input samples.\n",
        "            Must be of the same shape as training data.\n",
        "        :param y_test: np.array\n",
        "            Test target values.\n",
        "        :return: float\n",
        "            the cascade accuracy.\n",
        "        \"\"\"\n",
        "        casc_pred_prob = np.mean(self.cascade_forest(X_test), axis=0)\n",
        "        casc_pred = np.argmax(casc_pred_prob, axis=1)\n",
        "        casc_accuracy = accuracy_score(y_true=y_test, y_pred=casc_pred)\n",
        "        print('Layer validation accuracy = {}'.format(casc_accuracy))\n",
        "\n",
        "        return casc_accuracy\n",
        "\n",
        "    def _create_feat_arr(self, X, prf_crf_pred):\n",
        "        \"\"\" Concatenate the original feature vector with the predicition probabilities\n",
        "        of a cascade layer.\n",
        "        :param X: np.array\n",
        "            Array containing the input samples.\n",
        "            Must be of shape [n_samples, data] where data is a 1D array.\n",
        "        :param prf_crf_pred: list\n",
        "            Prediction probabilities by a cascade layer for X.\n",
        "        :return: np.array\n",
        "            Concatenation of X and the predicted probabilities.\n",
        "            To be used for the next layer in a cascade forest.\n",
        "        \"\"\"\n",
        "        swap_pred = np.swapaxes(prf_crf_pred, 0, 1)\n",
        "        add_feat = swap_pred.reshape([np.shape(X)[0], -1])\n",
        "        feat_arr = np.concatenate([add_feat, X], axis=1)\n",
        "\n",
        "        return feat_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NauKZBxLKRb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "  \n",
        "sns.set()\n",
        "url='https://raw.githubusercontent.com/blaze-nitd/mlproject/master/oasis_longitudinal.csv'\n",
        "df=pd.read_csv(url)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM6E4-RTKTZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f1f5cf9-da8e-4273-f989-e8dedb55e961"
      },
      "source": [
        "#df=df.loc[df['Visit']==1]\n",
        "df['M/F'] = df['M/F'].replace(['F','M'],[0,1])\n",
        "df['Group'] = df['Group'].replace(['Converted'],['Dementia'])\n",
        "df['Group'] = df['Group'].replace(['Dementia'],['Demented'])\n",
        "df['Group'] = df['Group'].replace(['Demented','Nondemented'],[1,0])\n",
        "\n",
        "df=df.drop(['Subject ID','MRI ID','Visit','Hand'],axis=1)\n",
        "\n",
        "print(df.shape)\n",
        "\n",
        "df = df.reset_index(drop='True')\n",
        "df.head()\n",
        "\n",
        "pd.isnull(df).sum()\n",
        "\n",
        "#Replace nan values in ['SES'] in correspondance to median of EDUC\n",
        "df['SES'].fillna(df.groupby('EDUC')['SES'].transform('median'), inplace = True)\n",
        "df['MMSE'].fillna(df.groupby('EDUC')['MMSE'].transform('median'), inplace = True)\n",
        "pd.isnull(df).sum()\n",
        "\n",
        "# Dataset with imputation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "Y = df['Group'].values # Target for the model\n",
        "X = df[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'MR Delay', 'CDR', 'eTIV', 'nWBV', 'ASF']] # Features we use\n",
        "\n",
        "# splitting into three sets\n",
        "X_train_unscaled, X_test_unscaled, y_train, y_test = train_test_split(X, Y, random_state=0)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = MinMaxScaler().fit(X_train_unscaled)\n",
        "X_train = scaler.transform(X_train_unscaled)\n",
        "X_test = scaler.transform(X_test_unscaled)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(373, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCLbWJrqKT8K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8a699495-57c8-4865-fd12-2da2d94a3888"
      },
      "source": [
        "gcf = gcForest(shape_1X=10, window=[2,4,6,8], tolerance=0.0)  \n",
        "gcf.fit(X_train, y_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Slicing Sequence...\n",
            "Training MGS Random Forests...\n",
            "Slicing Sequence...\n",
            "Training MGS Random Forests...\n",
            "Slicing Sequence...\n",
            "Training MGS Random Forests...\n",
            "Slicing Sequence...\n",
            "Training MGS Random Forests...\n",
            "Adding/Training Layer, n_layer=1\n",
            "Layer validation accuracy = 0.9642857142857143\n",
            "Adding/Training Layer, n_layer=2\n",
            "Layer validation accuracy = 0.9642857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCUOVWlFKdbJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d928ea9e-0bcb-4f0f-956a-19113b0fecf4"
      },
      "source": [
        "pred_X = gcf.predict(X_train)\n",
        "accuracy = accuracy_score(y_true=y_train, y_pred=pred_X)\n",
        "print('gcForest accuracy : {}'.format(accuracy))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Slicing Sequence...\n",
            "Slicing Sequence...\n",
            "Slicing Sequence...\n",
            "Slicing Sequence...\n",
            "gcForest accuracy : 0.946236559139785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ9NIHC8KYCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6e329018-9427-4866-de44-1fbcc0cbc651"
      },
      "source": [
        "pred_X = gcf.predict(X_test)\n",
        "accuracy = accuracy_score(y_true=y_test, y_pred=pred_X)\n",
        "print('gcForest Test accuracy : {}'.format(accuracy))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Slicing Sequence...\n",
            "Slicing Sequence...\n",
            "Slicing Sequence...\n",
            "Slicing Sequence...\n",
            "gcForest Test accuracy : 0.9468085106382979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bGR0HbJKhi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}